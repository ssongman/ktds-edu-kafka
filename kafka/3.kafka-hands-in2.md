# Kafka Hands-in 2

>Kafka On Kubernetes







# 1.  Producer 실습



## 1) key 와 partition 관계 이해

key 존재여부에 따라서 데이터가 어떻게 흘러가는지 확인해 보자.





키가 null 인 상태로 데이터 보내는데

파티션이 한개인 경우에는 데이터가 순서대로 쌓인다.

< 실습 >

1초에 한번씩 10개데이터를 보낸다.



이 상태에서 파티션 한개가 늘어난다면

키가 null 이므로 데이터는 라운드로빈 방식으로 쌓인다.

< 실습 >





키가 존재하는 데이터를 토픽에 보낸다면 어떻게 될까?

키가 존해할경우 kafka 는 key 를 특정한 hash 값으로 변형시켜서 파티션과 1대1 매칭을 시킨다.

그러므로 각 파티션에 동일한 key  값만 쌓에게 된다.

< 실습 >





파티션을 한개 더 추가 할경우 어떻게 될까?

토픽에 파티션을 추가하는 순간 키와 파티션의 일관성은 보장되지 않는다.

그러므로 key 를 사용할 경우  추후 생성하지 않는 것을 권장한다.

< 실습 >





## 2) 전송 보장과 ack 

### (1) 기본

* ack = 0
  * 서버 응답을 기다리지않음
  * 전송 보장도 zero
* ack = 1
  * 파티션의 리더에 저장되면 응답 받음
  * 리더 장애시 메시지 유실 가능
* ack = all(-1)
  * 모든 리플리카에 저장되면 응답 받음
    * 브로커 min.insync.replicas 설정에 따라 달라짐



### (2) 옵션에 따른 속도체크

* 리플리카 갯수 3, ack=0
  * 서버 응답을 기다리지 않음
* 리플리카 갯수 3, ack=1
  * 리더가 저장되면 성공 응답
* 리플리카 갯수 3, ack=all, min.insync.replicas = 1
  * 리더에 저장되면 성공 응답
  * ack=1과 동일(리더 장애시 메시지 유실 가능)
* 리플리카 갯수 3, ack=all, min.insync.replicas = 2
  * 리더에 저장하고 팔로워 중 한개에 저장하면 성공 응답
* 리플리카 갯수 3, ack=all, min.insync.replicas = 3
  * 리더와 팔로워 2개에 저장되면 성공 응답
  * 팔로워 중 한개라도 장애가 나면 리플리카 부족으로 저장에 실패함
  * 그러므로 이렇게 설정하는 것은 가능한 지양해야 함







## 3) Sender 동작

### (1) 기본동작

```
Send() --> Serializer --> Partitioner --> 버퍼(배치) --> Sender ==> 카프카브로커


```

* Sender
  * 별도 쓰레드로 Sender 가 동작한다.



### (2) batch.size linger.ms 에 따른 메세지 전송차이



* batch.size
  * 배치크기, 배치가 다 차면 바로 전송
  * 사이즈가 너무 작으면 한번에 보낼 수 있는 메시지의 건수가 줄고 처리량이 떨어진다.

* linger.ms
  * 전송대기시간(기본값 0)
  * 대기시간이 없으면 배치가 덜 차도 브로커로 바로 전송
  * 대기시간을 주면 그 시간 만큼 배치에 메시지 추가가 가능해서 한번의 전송 요청에 더 많은 데이터 처리가능
    * 처리량이 높아진다.





## 4) 전송결과 확인



### (1) future 이용

* Send method 가 리턴하는 future 를 활용해서 알수 있다.

* ```java
  Future<RecordMetadata> f = producer.send(new ProducerRecord<>("topic", "value"));
  try{
     RecordMetadata meta = f.get(); // 블록킹 처리된다.
  } catch (Exception ex) {
  
  }
  ```

* 

* 그 순간은 블로킹이 되면서 처리량이 저하된다.

* 처리량이 낮아도 되는 경우에만 사용한다.



### (2) Callback 사용

```
producer.send(new ProducerRecord<>("simple","value"),
   new Callback() {
      @Override
      public void onCompletion(RecordMetadata metadata, Exception ex) {
      
      }
   }
);
```

* 전송결과를 callback 으로 받을 수 있고 exception 이발생하면 전송이 실패한 경우이다.
* 블록킹되는 방식이 아니므로 배치가 쌓이지 않는 등의 단점이 사라진다.
* 처리량 저하 없음
* 







# 2. Consumer 실습



https://www.youtube.com/watch?v=5FEE5wVi8uY





## 1)  auto.offset.reset

Consumer Group 을 처음으로 접속을 시도할때 Topic 의 데이터를 가져오기 위한 옵션이다.



* latest : 가장 마지막 offset 부터
* earlist : 가장 처음 offset 부터 가져온다.















## 1) poll method



```
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(500)
  ...
}
```



poll method 가 지정한 시간동안 데이터가 들어오는 것을 기다린다.

설정값은 500ms 이므로 0.5 초동안 데이터가 유입되는 것을 기다리고 이후 아래 코드를 실행한다.







## 1) commit 

Auto Commit 과 Mannual Commit 에 대해서 알아보자.



### (1) AutoCommit

```
ConsumerConfig.enable_auto_commit_config = true
ConsumerConfig.auto_commit_interval_ms_config = 60000   ; 60초마다 자동으로 commit 수행한다.
```

일정 간격으로 자동 commit



테스트 시나리오

1) Program 을 수행시켜서 Consum 하자.
2) poll() 60초이전에 Program Stop을 눌러버리자.
3) 다시 해당 consumer 를 기동
4) 그럼 초기에 Consume 했던 데이터가 다시 읽어 진다.
5) Commit 되지않았으므로 당연히 두번 읽어진다.
6) 중복처리될 가능성이 있음



특징

* enable.auto.commit = true 가 기본 옵션이다.

* 속도가 빠름
* 중복 또는 유실이 발생할 수 있음
  * 중복/유실을 허용하지 않는 곳에서는 절대 사용금지
  * 



### (2) 수동커밋

enable.auto.commit=false

* commitSync()
  * ConsumerRecord 처리순서를보장함
  * 속도가느리다.
  * consumer 가 읽어드린 마지막 offset을 커밋한다.
  * Map 을 통해 오프셋 지정 커밋 가능

* commitAsync()
  * 동기 커밋 보다 빠름
  * 중복 발생가능
    * 이전offset 보다 이후 offset 이 먼저 커밋되는 경우
  * 처리순서 보장 못함



테스트시나리오

* commitSync() 옵션으로 프로그램 수행
* 프로듀서1~5,  consumer 1-5 수행
* 프로그램 중지
* 프로듀서 전송 6~10
* 프로그램 수행
* 6~10 확인









## 2) concurrency 옵션



## 3) graceful shutdown 방법





Stop 을



## 9) 데이터 유실에 대한 대처







